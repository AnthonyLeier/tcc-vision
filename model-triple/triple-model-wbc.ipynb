{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "colab_type": "text",
        "id": "vPs64QA1Zdov"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "import os\r\n",
        "import random\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "import xml.etree.ElementTree as ET\r\n",
        "\r\n",
        "from PIL import Image, ImageDraw\r\n",
        "from numpy import asarray\r\n",
        "from bs4 import BeautifulSoup as bs\r\n",
        "\r\n",
        "from object_detection.utils import config_util, visualization_utils as viz_utils\r\n",
        "from object_detection.builders import model_builder\r\n",
        "\r\n",
        "%matplotlib inline"
      ],
      "outputs": [],
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "uZcqD4NLdnf4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "porcentagem_acerto = 0.1"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Funções de Controle de Imagem"
      ],
      "metadata": {
        "colab_type": "text",
        "id": "IogyryF2lFBL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def existeWBC(arquivo):\r\n",
        "    content = []\r\n",
        "    with open(arquivo, \"r\") as file:\r\n",
        "        content = file.readlines()\r\n",
        "        content = \"\".join(content)\r\n",
        "        bs_content = bs(content, \"lxml\")\r\n",
        "        lista_objetos = bs_content.find_all(\"object\")\r\n",
        "\r\n",
        "        for objeto in lista_objetos:\r\n",
        "            nome = objeto.find(\"name\")\r\n",
        "            if \"WBC\" in nome:\r\n",
        "                return True\r\n",
        "\r\n",
        "    return False"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def criarArquivo(mensagem, path):\r\n",
        "    path = path.replace(\"imagens\", \"info\")\r\n",
        "    path = path.replace(\".jpg\", \".txt\")\r\n",
        "    mensagem = mensagem.replace(\"WBCs\", \"\")\r\n",
        "    arquivo = open(path, \"w\")\r\n",
        "    arquivo.write(\"WBC\\n\")\r\n",
        "    arquivo.write(mensagem)\r\n",
        "    arquivo.close()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Converte a imagem em array\r\n",
        "def convertImageToArray(path):\r\n",
        "    image = Image.open(path)\r\n",
        "    array = asarray(image)\r\n",
        "    return array\r\n",
        "\r\n",
        "\r\n",
        "# Imprime as detecções na imagem\r\n",
        "def plotDetections(imagem, boxes, classes, scores, categoria, nome=None):\r\n",
        "    imagemDeteccao = imagem.copy()\r\n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\r\n",
        "        imagemDeteccao, boxes, classes, scores, categoria, use_normalized_coordinates=True, min_score_thresh=porcentagem_acerto)\r\n",
        "\r\n",
        "    if nome:\r\n",
        "        pontuacao = np.squeeze(scores)\r\n",
        "        contador = 0\r\n",
        "        for i in range(100):\r\n",
        "            if scores is None or pontuacao[i] > porcentagem_acerto:\r\n",
        "                contador = contador + 1\r\n",
        "\r\n",
        "        mensagem = str(contador) + \" WBCs\"\r\n",
        "\r\n",
        "        plt.imsave(nome, imagemDeteccao)\r\n",
        "        img = Image.open(nome)\r\n",
        "        editor = ImageDraw.Draw(img)\r\n",
        "        editor.text((10, 10), mensagem, fill=(255, 255, 0))\r\n",
        "\r\n",
        "        criarArquivo(mensagem, nome)\r\n",
        "\r\n",
        "        img.save(nome)\r\n",
        "    else:\r\n",
        "        plt.imshow(imagemDeteccao)\r\n"
      ],
      "outputs": [],
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "-y9R0Xllefec"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Análise dos Dados"
      ],
      "metadata": {
        "colab_type": "text",
        "id": "sSaXL28TZfk1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "train_images_dir = './dataset-triple/train/imagens/'\r\n",
        "train_images = []\r\n",
        "\r\n",
        "# Coleta as imagens, converte em array e salva em array geral\r\n",
        "for elemento in os.listdir(train_images_dir):\r\n",
        "    imagem = os.path.join(train_images_dir, elemento)\r\n",
        "    info = imagem.replace(\"imagens\", \"coordenadas\")\r\n",
        "    info = info.replace(\"jpg\", \"xml\")\r\n",
        "    if existeWBC(info):\r\n",
        "        train_images.append(convertImageToArray(imagem))\r\n",
        "\r\n",
        "# Parâmetros para a plotagem\r\n",
        "plt.rcParams['axes.grid'] = False\r\n",
        "plt.rcParams['xtick.labelsize'] = False\r\n",
        "plt.rcParams['ytick.labelsize'] = False\r\n",
        "plt.rcParams['xtick.top'] = False\r\n",
        "plt.rcParams['xtick.bottom'] = False\r\n",
        "plt.rcParams['ytick.left'] = False\r\n",
        "plt.rcParams['ytick.right'] = False\r\n",
        "plt.rcParams['figure.figsize'] = [14, 7]\r\n",
        "\r\n",
        "# Plotagem da visualização teste\r\n",
        "for indice in range(0, 6):\r\n",
        "    plt.subplot(2, 3, indice+1)\r\n",
        "    plt.imshow(train_images[indice])\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "SQy3ND7EpFQM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Leitura das Coordenadas"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Função para realizar a conversão das coordenadas do XML para o formato utilizado no plot\r\n",
        "def calcularPosicao(lista):\r\n",
        "    xmin = lista[0]\r\n",
        "    ymin = lista[1]\r\n",
        "    xmax = lista[2]\r\n",
        "    ymax = lista[3]\r\n",
        "\r\n",
        "    larguraImagem = 640\r\n",
        "    alturaImagem = 480\r\n",
        "\r\n",
        "    xmin = xmin / larguraImagem\r\n",
        "    ymin = ymin / alturaImagem\r\n",
        "    xmax = xmax / larguraImagem\r\n",
        "    ymax = ymax / alturaImagem\r\n",
        "\r\n",
        "    return [ymin, xmin, ymax, xmax]"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Função para coletar as coordenadas do arquivo XML\r\n",
        "def encontraWBC(arquivo):\r\n",
        "    content = []\r\n",
        "    with open(arquivo, \"r\") as file:\r\n",
        "        content = file.readlines()\r\n",
        "        content = \"\".join(content)\r\n",
        "        bs_content = bs(content, \"lxml\")\r\n",
        "\r\n",
        "        lista_objetos = bs_content.find_all(\"object\")\r\n",
        "        for objeto in lista_objetos:\r\n",
        "            nome = objeto.find(\"name\")\r\n",
        "            xmin = objeto.find(\"xmin\")\r\n",
        "            ymin = objeto.find(\"ymin\")\r\n",
        "            xmax = objeto.find(\"xmax\")\r\n",
        "            ymax = objeto.find(\"ymax\")\r\n",
        "\r\n",
        "            if \"WBC\" in nome:\r\n",
        "                nome = str(nome)\r\n",
        "                xmin = str(xmin)\r\n",
        "                ymin = str(ymin)\r\n",
        "                xmax = str(xmax)\r\n",
        "                ymax = str(ymax)\r\n",
        "\r\n",
        "                # newNome = nome[nome.find(\">\")+1:nome.find(\"</name>\")]\r\n",
        "                newXmin = int(xmin[xmin.find(\">\")+1:xmin.find(\"</xmin>\")])\r\n",
        "                newYmin = int(ymin[ymin.find(\">\")+1:ymin.find(\"</ymin>\")])\r\n",
        "                newXmax = int(xmax[xmax.find(\">\")+1:xmax.find(\"</xmax>\")])\r\n",
        "                newYmax = int(ymax[ymax.find(\">\")+1:ymax.find(\"</ymax>\")])\r\n",
        "\r\n",
        "                return [newXmin, newYmin, newXmax, newYmax]\r\n",
        "                \r\n",
        "    return False\r\n",
        "\r\n",
        "print(encontraWBC(\"dataset-triple/train/coordenadas/BloodImage_00125.xml\"))"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Importação das coordenadas para um array\r\n",
        "coordenadas_dir = 'dataset-triple/train/coordenadas/'\r\n",
        "coordenadas_info = []\r\n",
        "\r\n",
        "for arquivo in os.listdir(coordenadas_dir):\r\n",
        "    if existeWBC(coordenadas_dir + arquivo):\r\n",
        "        coordenadas_info.append(np.array(\r\n",
        "            [calcularPosicao(encontraWBC(coordenadas_dir + arquivo))], dtype=np.float32))\r\n",
        "\r\n",
        "for i in range(0, 6):\r\n",
        "    print(coordenadas_info[i])"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparando dados para treinamento"
      ],
      "metadata": {
        "colab_type": "text",
        "id": "Dqb_yjAo3cO_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Definição da classe\r\n",
        "wbc_id = 1\r\n",
        "num_classes = 1\r\n",
        "categorias = {wbc_id: {'id': wbc_id, 'name': 'wbc'}}\r\n",
        "\r\n",
        "train_images_tensors = []\r\n",
        "coordenadas_info_tensors = []\r\n",
        "offset = 1\r\n",
        "classes_tensors = []\r\n",
        "\r\n",
        "# Função Zip = Tupla entre dois arryas (Imagens + Coordenadas)\r\n",
        "for (train_image, coordenada) in zip(train_images, coordenadas_info):\r\n",
        "    train_images_tensors.append(tf.expand_dims(tf.convert_to_tensor(train_image, dtype=tf.float32), axis=0))\r\n",
        "    coordenadas_info_tensors.append(tf.convert_to_tensor(coordenada, dtype=tf.float32))\r\n",
        "    indices = tf.convert_to_tensor(np.ones(shape=[coordenada.shape[0]], dtype=np.int32) - offset)\r\n",
        "    classes_tensors.append(tf.one_hot(indices, num_classes))\r\n",
        "\r\n",
        "print('Dados preparados')"
      ],
      "outputs": [],
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "HWBqFVMcweF-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizando imagens com coordenadas"
      ],
      "metadata": {
        "colab_type": "text",
        "id": "b3_Z3mJWN9KJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(len(train_images))\r\n",
        "print(len(coordenadas_info))"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "fake_score = np.array([1.0], dtype=np.float32)\r\n",
        "\r\n",
        "plt.figure(figsize=(30, 15))\r\n",
        "for indice in range(0, 6):\r\n",
        "    plt.subplot(2, 3, indice+1)\r\n",
        "    plotDetections(\r\n",
        "        train_images[indice],\r\n",
        "        coordenadas_info[indice],\r\n",
        "        np.ones(shape=[coordenadas_info[indice].shape[0]], dtype=np.int32),\r\n",
        "        fake_score, categorias)\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "YBD6l-E4N71y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Criar modelo e trabalhar com checkpoints"
      ],
      "metadata": {
        "colab_type": "text",
        "id": "ghDAsqfoZvPh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "tf.keras.backend.clear_session()\r\n",
        "print('Construindo modelo e restaurando pesos para fine-tuning...', flush=True)\r\n",
        "\r\n",
        "# Parâmetros do modelo\r\n",
        "num_classes = 1\r\n",
        "pipeline_config = '../models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/pipeline.config'\r\n",
        "checkpoint_path = '../models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0'\r\n",
        "\r\n",
        "# Salvar checkpoint e configurações\r\n",
        "output_directory = '../prototype/saves/wbc/'\r\n",
        "output_checkpoint_dir = os.path.join(output_directory, 'checkpoint')\r\n",
        "\r\n",
        "# Importação e definição\r\n",
        "configs = config_util.get_configs_from_pipeline_file(pipeline_config)\r\n",
        "model_config = configs['model']\r\n",
        "model_config.ssd.num_classes = num_classes\r\n",
        "model_config.ssd.freeze_batchnorm = True\r\n",
        "\r\n",
        "# Construção do Modelo\r\n",
        "model = model_builder.build(model_config=model_config, is_training=True)\r\n",
        "\r\n",
        "# Salvar pipeline config\r\n",
        "pipeline_proto = config_util.create_pipeline_proto_from_configs(configs)\r\n",
        "config_util.save_pipeline_config(pipeline_proto, output_directory)\r\n",
        "\r\n",
        "fakebox_predictor = tf.compat.v2.train.Checkpoint(_base_tower_layers_for_heads=model._box_predictor._base_tower_layers_for_heads,\r\n",
        "                                                  _box_prediction_head=model._box_predictor._box_prediction_head)\r\n",
        "fake_model = tf.compat.v2.train.Checkpoint(\r\n",
        "    _feature_extractor=model._feature_extractor, _box_predictor=fakebox_predictor)\r\n",
        "\r\n",
        "checkpoint = tf.compat.v2.train.Checkpoint(model=fake_model)\r\n",
        "checkpoint.restore(checkpoint_path).expect_partial()\r\n",
        "\r\n",
        "image, shapes = model.preprocess(tf.zeros([1, 640, 640, 3]))\r\n",
        "prediction_dict = model.predict(image, shapes)\r\n",
        "_ = model.postprocess(prediction_dict, shapes)\r\n",
        "print('Pesos restaurados!')"
      ],
      "outputs": [],
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "RyT4BUbaMeG-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loop de treinamento personalizado"
      ],
      "metadata": {
        "colab_type": "text",
        "id": "pCkWmdoZZ0zJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "tf.keras.backend.set_learning_phase(True)\r\n",
        "\r\n",
        "# Valores padrão\r\n",
        "# batch_size = 4\r\n",
        "# learning_rate = 0.01\r\n",
        "# num_batches = 100\r\n",
        "\r\n",
        "# Mehlores valores até agora\r\n",
        "# batch_size = 24\r\n",
        "# learning_rate = 0.02\r\n",
        "# num_batches = 200\r\n",
        "\r\n",
        "batch_size = 4\r\n",
        "learning_rate = 0.01\r\n",
        "num_batches = 10\r\n",
        "\r\n",
        "# Variáveis do Treinamento\r\n",
        "variaveis_treino = model.trainable_variables\r\n",
        "ajuste_fino = []\r\n",
        "prefixo_treino = ['WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead',\r\n",
        "                  'WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead']\r\n",
        "\r\n",
        "for variavel in variaveis_treino:\r\n",
        "    if any([variavel.name.startswith(prefix) for prefix in prefixo_treino]):\r\n",
        "        ajuste_fino.append(variavel)\r\n",
        "\r\n",
        "def passoTreino(model, otimizador, ajuste_fino):\r\n",
        "    @tf.function\r\n",
        "    def passo(imagem_tensors, boxes_list, classes_list):\r\n",
        "\r\n",
        "        forma = tf.constant(batch_size * [[640, 640, 3]], dtype=tf.int32)\r\n",
        "        model.provide_groundtruth(\r\n",
        "            groundtruth_boxes_list=boxes_list, groundtruth_classes_list=classes_list)\r\n",
        "\r\n",
        "        with tf.GradientTape() as tape:\r\n",
        "            prepro_images = tf.concat([model.preprocess(imagem_tensor)[\r\n",
        "                                      0] for imagem_tensor in imagem_tensors], axis=0)\r\n",
        "            predicao_dict = model.predict(prepro_images, forma)\r\n",
        "            perdas_dict = model.loss(predicao_dict, forma)\r\n",
        "            perda_total = perdas_dict['Loss/localization_loss'] + \\\r\n",
        "                perdas_dict['Loss/classification_loss']\r\n",
        "            gradientes = tape.gradient(perda_total, ajuste_fino)\r\n",
        "            otimizador.apply_gradients(zip(gradientes, ajuste_fino))\r\n",
        "        return perda_total\r\n",
        "\r\n",
        "    return passo\r\n",
        "\r\n",
        "otimizador = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9)\r\n",
        "passoTreino = passoTreino(model, otimizador, ajuste_fino)\r\n",
        "\r\n",
        "print('Fine-tuning inicializado!', flush=True)\r\n",
        "for indice in range(num_batches):\r\n",
        "    chaves = list(range(len(train_images)))\r\n",
        "    random.shuffle(chaves)\r\n",
        "    exemplo_chaves = chaves[:batch_size]\r\n",
        "\r\n",
        "    boxes_list = [coordenadas_info_tensors[chave] for chave in exemplo_chaves]\r\n",
        "    classes_list = [classes_tensors[chave] for chave in exemplo_chaves]\r\n",
        "    image_tensors = [train_images_tensors[chave] for chave in exemplo_chaves]\r\n",
        "\r\n",
        "    perda_total = passoTreino(image_tensors, boxes_list, classes_list)\r\n",
        "\r\n",
        "    if indice % 10 == 0:\r\n",
        "        print('Batch ' + str(indice) + ' of ' + str(num_batches)\r\n",
        "              + ', Loss = ' + str(perda_total.numpy()), flush=True)\r\n",
        "\r\n",
        "print('Fine-tuning realizado!')"
      ],
      "outputs": [],
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "nyHoF4mUrv5-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carregar imagens para teste e aplicar no modelo"
      ],
      "metadata": {
        "colab_type": "text",
        "id": "WHlXL1x_Z3tc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "modelo = pipeline_config\r\n",
        "modelo = modelo.replace(\"../models/\", \"\")\r\n",
        "modelo = modelo.replace(\"/pipeline.config\", \"\")\r\n",
        "\r\n",
        "resultados = str(batch_size) + \"_\" + str(learning_rate) + \"_\" + str(num_batches) + \"_\" + str(porcentagem_acerto) + \"_\" + str(modelo)\r\n",
        "\r\n",
        "resultados_path = \"./results-triple/\" + str(resultados)\r\n",
        "imagem_path = resultados_path + \"/wbc/imagens/\"\r\n",
        "info_path = resultados_path + \"/wbc/info/\" \r\n",
        "\r\n",
        "print(resultados_path)\r\n",
        "if not os.path.isdir(imagem_path):\r\n",
        "    os.makedirs(imagem_path)\r\n",
        "if not os.path.isdir(info_path):\r\n",
        "    os.makedirs(info_path)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "test_image_dir = 'dataset-triple/test/imagens/'\r\n",
        "test_images = []\r\n",
        "test_images_nomes = []\r\n",
        "\r\n",
        "for elemento in os.listdir(test_image_dir):\r\n",
        "    imagem = os.path.join(test_image_dir, elemento)\r\n",
        "    test_images_nomes.append(elemento)\r\n",
        "    test_images.append(np.expand_dims(convertImageToArray(imagem), axis=0))\r\n",
        "\r\n",
        "@tf.function\r\n",
        "def detectar(input_tensor):\r\n",
        "    prepross_image, formas = model.preprocess(input_tensor)\r\n",
        "    predicao_dict = model.predict(prepross_image, formas)\r\n",
        "    return model.postprocess(predicao_dict, formas)\r\n",
        "\r\n",
        "offset = 1\r\n",
        "for i in range(len(test_images)):\r\n",
        "    test_tensor = tf.convert_to_tensor(test_images[i], dtype=tf.float32)\r\n",
        "    deteccoes = detectar(test_tensor)\r\n",
        "\r\n",
        "    plotDetections(\r\n",
        "        test_images[i][0],\r\n",
        "        deteccoes['detection_boxes'][0].numpy(),\r\n",
        "        deteccoes['detection_classes'][0].numpy().astype(np.uint32) + offset,\r\n",
        "        deteccoes['detection_scores'][0].numpy(),\r\n",
        "        categorias, nome=imagem_path + test_images_nomes[i])"
      ],
      "outputs": [],
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "WcE6OwrHQJya"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import servidor\r\n",
        "servidor.start(model, \"./dataset-triple/test/imagens/BloodImage_00333.jpg\")"
      ],
      "outputs": [],
      "metadata": {}
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "interactive_eager_few_shot_od_training_colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.7 64-bit"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.7",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}